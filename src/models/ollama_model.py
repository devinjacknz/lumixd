"""
Ollama Model Integration
Handles interaction with local Ollama API
"""

import os
import json
import requests
from .base_model import BaseModel, ModelResponse

class OllamaModel(BaseModel):
    @property
    def AVAILABLE_MODELS(self):
        return ['deepseek-r1:1.5b']
    
    def __init__(self, model_name="deepseek-r1:1.5b"):
        super().__init__()
        self.model_name = model_name
        self.api_url = "http://localhost:11434/api/generate"
        self.headers = {"Content-Type": "application/json"}
        self.client = None
        self.initialize_client()
        
    def initialize_client(self):
        """Initialize connection to Ollama API"""
        try:
            response = requests.get("http://localhost:11434/api/tags")
            response.raise_for_status()
            self.client = True
            print("âœ¨ Successfully connected to Ollama API")
            print(f"ğŸ“š Available Ollama models: {self.AVAILABLE_MODELS}")
            return True
        except Exception as e:
            print(f"Error connecting to Ollama API: {e}")
            return False
            
    def is_available(self):
        """Check if model is available"""
        return self.client is not None
        
    @property
    def model_type(self):
        """Get model type"""
        return "ollama"
        
    def generate_response(self, system_prompt, user_content, temperature=0.7):
        """Generate response from Ollama model"""
        if not self.is_available():
            print("Model not initialized")
            return None
            
        try:
            # Format prompt to encourage JSON response
            formatted_prompt = f"""
{system_prompt}

è¯·ç”¨JSONæ ¼å¼å›å¤ã€‚ç¡®ä¿å›å¤ä»¥ '{{' å¼€å§‹ï¼Œä»¥ '}}' ç»“æŸã€‚
Please respond in JSON format. Ensure the response starts with '{{' and ends with '}}'.

{user_content}
"""
            data = {
                "model": self.model_name,
                "prompt": formatted_prompt,
                "temperature": temperature,
                "stream": True  # Use streaming mode
            }
            
            # Stream response and collect all chunks
            full_response = ""
            with requests.post(self.api_url, json=data, headers=self.headers, stream=True) as response:
                response.raise_for_status()
                for line in response.iter_lines():
                    if line:
                        try:
                            chunk = json.loads(line)
                            if 'response' in chunk:
                                full_response += chunk['response']
                        except json.JSONDecodeError:
                            continue
            
            # Clean up and parse JSON from full response
            try:
                # Remove code blocks and clean whitespace
                content = full_response.replace('```json', '').replace('```', '').strip()
                content = ' '.join(line.strip() for line in content.split('\n'))
                
                # Find JSON content
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                
                if start_idx >= 0 and end_idx > start_idx:
                    json_str = content[start_idx:end_idx + 1]
                    parsed_content = json.loads(json_str)
                    
                    return ModelResponse(
                        content=json.dumps(parsed_content),
                        raw_response={'response': full_response}
                    )
                        
            except json.JSONDecodeError as e:
                print(f"Error parsing JSON: {e}")
                pass
                
            # Return raw response if JSON parsing fails
            return ModelResponse(
                content=content,
                raw_response=response.json()
            )
            
        except Exception as e:
            print(f"Error generating response: {e}")
            return None
            
    async def analyze_trade(self, instruction: str) -> dict:
        """Analyze trading instruction and return structured data"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Solanaç”Ÿæ€DeFiäº¤æ˜“åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·çš„äº¤æ˜“æŒ‡ä»¤å¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚

ç¤ºä¾‹è¾“å…¥ | Example input:
"ä¹°å…¥500ä¸ªSOLä»£å¸ï¼Œæ»‘ç‚¹ä¸è¶…è¿‡2%"
"Buy 500 SOL tokens with max 2% slippage"

ç¤ºä¾‹è¾“å‡º | Example output:
{
    "trade_type": "buy",
    "token": "SOL",
    "amount": "500",
    "slippage": "2",
    "input_mint": "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v",
    "output_mint": "So11111111111111111111111111111111111111112"
}"""
        
        response = self.generate_response(
            system_prompt=system_prompt,
            user_content=instruction,
            temperature=0.7
        )
        
        if not response:
            return {
                'error': 'Failed to generate response',
                'error_cn': 'æ— æ³•ç”Ÿæˆå“åº”'
            }
            
        try:
            # Try to parse JSON from response
            content = response.content
            if isinstance(content, str):
                # Look for JSON-like structure
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                if start_idx >= 0 and end_idx > start_idx:
                    json_str = content[start_idx:end_idx + 1]
                    result = json.loads(json_str)
                    return result
                    
            return {
                'error': 'Invalid response format',
                'error_cn': 'å“åº”æ ¼å¼æ— æ•ˆ'
            }
        except json.JSONDecodeError:
            return {
                'error': 'Failed to parse response',
                'error_cn': 'æ— æ³•è§£æå“åº”'
            }
            
    async def check_risk_dialogue(self, trade_request: dict) -> dict:
        """Risk check with bilingual dialogue"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é£é™©ç®¡ç†åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æäº¤æ˜“é£é™©ã€‚
You are a professional risk management assistant analyzing trade risks.

è¯·åˆ†æä»¥ä¸‹äº¤æ˜“é£é™©å¹¶è¿”å›JSONæ ¼å¼ç»“æœ | Please analyze the following trade risk and return JSON result:

ç¤ºä¾‹è¾“å‡º | Example output:
{
    "risk_level": "low/medium/high",
    "approved": true/false,
    "reason": "Risk analysis explanation in both languages",
    "warnings": ["Warning 1", "è­¦å‘Š 1"],
    "suggestions": ["Suggestion 1", "å»ºè®® 1"]
}"""
        
        risk_prompt = f"""
åˆ†æä»¥ä¸‹äº¤æ˜“é£é™© | Analyze trade risk:
ä»£å¸ | Token: {trade_request.get('token', 'Unknown')}
æ•°é‡ | Amount: {trade_request.get('amount', '0')}
æ–¹å‘ | Direction: {trade_request.get('direction', 'Unknown')}
æ»‘ç‚¹ | Slippage: {trade_request.get('slippage', '2.5')}%"""
        
        response = self.generate_response(
            system_prompt=system_prompt,
            user_content=risk_prompt,
            temperature=0.7
        )
        
        if not response:
            return {
                'error': 'Failed to generate response',
                'error_cn': 'æ— æ³•ç”Ÿæˆå“åº”',
                'approved': False
            }
            
        try:
            # Try to parse JSON from response
            content = response.content
            if isinstance(content, str):
                # Look for JSON-like structure
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                if start_idx >= 0 and end_idx > start_idx:
                    json_str = content[start_idx:end_idx + 1]
                    result = json.loads(json_str)
                    return result
                    
            return {
                'error': 'Invalid response format',
                'error_cn': 'å“åº”æ ¼å¼æ— æ•ˆ',
                'approved': False
            }
        except json.JSONDecodeError:
            return {
                'error': 'Failed to parse response',
                'error_cn': 'æ— æ³•è§£æå“åº”',
                'approved': False
            }              